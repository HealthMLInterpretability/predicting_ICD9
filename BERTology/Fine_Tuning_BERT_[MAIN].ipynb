{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtp4VzZ1vTFx"
      },
      "source": [
        "#### Notes:\n",
        "- Make sure you are switched to GPU\n",
        "- Code is not cleaned and not reviewed yet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqY-WJGsqYr1"
      },
      "source": [
        "# ***Loading Packages*** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNUIemXMqPkQ",
        "outputId": "d857b20b-921c-487d-cba5-676b5a0d3bcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.7/dist-packages (2.8.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (2.8.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.14.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (13.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.10.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.21.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.44.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.24.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.0.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.5.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.17.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.3.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjZWbkDVriFR",
        "outputId": "1d090a5f-5470-4117-b69a-35d5838adb33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "np.set_printoptions(precision=2, linewidth=80)\n",
        "import torch\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "stop_words = set(stopwords.words('english'))\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "english_stopwords = stopwords.words('english')\n",
        "stemmer = SnowballStemmer('english')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import (BertForSequenceClassification, BertTokenizer, AdamW, BertConfig, get_linear_schedule_with_warmup)\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn import preprocessing\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import sklearn.metrics as metrics\n",
        "import operator\n",
        "import random\n",
        "import time\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRqQn2EsRawm",
        "outputId": "a11545a1-fd95-414d-c289-dff15eb3b745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nltk.download('wordnet')\n",
        "all_stopwords = nlp.Defaults.stop_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PHotgP0pCnB"
      },
      "outputs": [],
      "source": [
        "tokenizer = ToktokTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSDRkVH5PCi1",
        "outputId": "a5a5da2c-e739-4e1d-f375-96780202d4e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla K80\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():        \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('CPU is exist.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ig7nJ5lz2W3W",
        "outputId": "bef9a2b6-6407-4f3e-b869-6f60430f7670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5FNBoI0lwLt"
      },
      "outputs": [],
      "source": [
        "# loading base BERT tokenizer\n",
        "tokenizerBERT = BertTokenizer.from_pretrained(\"bert-base-uncased\") # 'bert-base-uncased' original"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfevenucl8i9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac5432d-d64d-4418-d7a4-018bb3922737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    # \"bert-base-uncased\",   original \n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 2,                 \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = True,  # originally False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IN-3yG3YdveR",
        "outputId": "d5a17466-4276-44fd-9618-3dc625eb7dd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqTUvjS3DlGS"
      },
      "source": [
        "# 1. Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teris5HRstUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e36626-772d-46dd-c7df-484e37f99e00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "\n",
        "# ICD_train = pd.read_csv('/gdrive/MyDrive/dataset/DIA_GROUPS_3_DIGITS_adm_train.csv')\n",
        "# ICD_test = pd.read_csv('/gdrive/MyDrive/dataset/DIA_GROUPS_3_DIGITS_adm_test.csv')\n",
        "# ICD_val = pd.read_csv('/gdrive/MyDrive/dataset/DIA_GROUPS_3_DIGITS_adm_val.csv')\n",
        "\n",
        "# # noteevents_df = pd.read_csv(\"/gdrive/My Drive/dataset/NOTEEVENTS.csv\") \n",
        "# # icd_df = pd.read_csv(\"/gdrive/My Drive/dataset/DIAGNOSES_ICD.csv\")\n",
        "# # admin_df = pd.read_csv(\"/gdrive/My Drive/dataset/ADMISSIONS.csv\")\n",
        "\n",
        "# # df = pd.read_csv(\"/gdrive/My Drive/dataset/dataset_cleaned.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVgKWEv7-KoW",
        "outputId": "506a0ba0-9ffd-49e9-f0d1-b5e3621569ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df =  pd.read_csv(\"/content/drive/MyDrive/AI Projects and Dataset/Health ML/IMDB Dataset.csv\")"
      ],
      "metadata": {
        "id": "9SHwhuHB-NLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eoXkAon3--lL",
        "outputId": "bbc0960b-b0bb-4091-fbd4-8ae2e11c602a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text     label\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef600ebc-8eb3-40b3-aeb1-a39bf175867e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef600ebc-8eb3-40b3-aeb1-a39bf175867e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef600ebc-8eb3-40b3-aeb1-a39bf175867e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef600ebc-8eb3-40b3-aeb1-a39bf175867e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns={\"index\"}, inplace = True)\n",
        "df = df.rename(columns = {'review':'text', 'sentiment':'label'})"
      ],
      "metadata": {
        "id": "JTRRq3If--Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yRfkcLVs_AJb",
        "outputId": "7ec49d5f-217f-4552-a19b-f872650d07b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text     label\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7b678d3-793f-462e-88b0-ab72866772b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7b678d3-793f-462e-88b0-ab72866772b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7b678d3-793f-462e-88b0-ab72866772b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7b678d3-793f-462e-88b0-ab72866772b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "nhbrV2Sl_hmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing the html strips\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    return text\n",
        "#Apply function on review column\n",
        "df['text']=df['text'].apply(denoise_text)"
      ],
      "metadata": {
        "id": "dUnaPsHV_Z4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_special_characters(text, remove_digits=True):\n",
        "    pattern=r'[^a-zA-z0-9\\s]'\n",
        "    text=re.sub(pattern,'',text)\n",
        "    return text\n",
        "#Apply function on review column\n",
        "df['text']=df['text'].apply(remove_special_characters)"
      ],
      "metadata": {
        "id": "N-wyuCsd_n3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_stemmer(text):\n",
        "    ps=nltk.porter.PorterStemmer()\n",
        "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
        "    return text\n",
        "#Apply function on review column\n",
        "df['text']=df['text'].apply(simple_stemmer)"
      ],
      "metadata": {
        "id": "zDVd2_7j_urr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopword_list=nltk.corpus.stopwords.words('english')"
      ],
      "metadata": {
        "id": "-VWQ5X9nAncr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop=set(stopwords.words('english'))\n",
        "print(stop)\n",
        "\n",
        "#removing the stopwords\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text\n",
        "#Apply function on review column\n",
        "df['text']=df['text'].apply(remove_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13-dLJ0C_x8u",
        "outputId": "d2138021-3c8f-4b29-8a52-3b97907e6fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"she's\", \"won't\", \"wouldn't\", 'again', 'their', 'been', 'no', \"should've\", 't', 'when', 'on', 'with', 'to', \"shan't\", \"couldn't\", 'there', 'where', 're', 'being', 'such', 'aren', 'him', 'those', 'our', 'd', 'between', 'off', 'both', 'so', 'here', 'herself', 'below', 'it', 'theirs', 'of', 'your', 'won', \"hasn't\", 'weren', \"mustn't\", 'didn', 'how', 'which', 'each', 'himself', \"hadn't\", 'some', 'under', \"don't\", 'why', 'who', 'whom', 'into', 'very', 'y', 'through', 'don', 'we', 'by', 'yourselves', 'them', 'during', 'after', 'yours', 'doing', 'shan', 'too', 'all', 'mustn', 'should', \"needn't\", 'a', 'had', 'if', 'before', 'wouldn', 've', 'these', 'while', 'has', 'ours', 'm', 'hadn', \"haven't\", 'down', 'and', 'me', 'they', 'my', 'just', 'his', \"isn't\", 'was', 'having', 'same', \"you'd\", 'will', \"didn't\", 'any', 'more', 'have', \"weren't\", 'few', 'be', 'doesn', 'did', 'do', 'is', 'about', \"wasn't\", 'hasn', 'not', 'at', \"you've\", 'does', 'now', \"you'll\", 'were', 'o', 'but', 'ain', 'can', 'yourself', 'own', 'haven', 'shouldn', 'myself', 'he', 'she', 'above', 'up', 'you', 'this', 'itself', 'ma', 'am', 'in', 'because', 'until', 'themselves', 'as', 'the', 'hers', 'against', 'i', 'an', 'mightn', \"doesn't\", 'than', 'once', 'isn', 'her', 'out', \"shouldn't\", 'then', 'other', 'from', 'further', 's', 'couldn', 'over', 'that', \"you're\", \"that'll\", \"it's\", 'its', 'most', 'only', 'wasn', 'or', 'what', 'for', 'nor', 'll', \"mightn't\", 'needn', 'ourselves', 'are', \"aren't\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "id": "qE9tKZdMBB6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = preprocessing.LabelEncoder()"
      ],
      "metadata": {
        "id": "XPXG9vEjBMPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.label = label_encoder.fit_transform(df.label)"
      ],
      "metadata": {
        "id": "dPqiE0cYBjiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1AIytussB0Nq",
        "outputId": "a05f9f2f-488a-4113-cfed-7eba216cfa27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  one review ha mention watch 1 Oz episod youll ...      1\n",
              "1  wonder littl product film techniqu veri unassu...      1\n",
              "2  thought thi wa wonder way spend time hot summe...      1\n",
              "3  basic famili littl boy jake think zombi hi clo...      0\n",
              "4  petter mattei love time money visual stun film...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17f1c9b4-e145-41ea-b462-2e21ffde3d70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one review ha mention watch 1 Oz episod youll ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wonder littl product film techniqu veri unassu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thought thi wa wonder way spend time hot summe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basic famili littl boy jake think zombi hi clo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei love time money visual stun film...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17f1c9b4-e145-41ea-b462-2e21ffde3d70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-17f1c9b4-e145-41ea-b462-2e21ffde3d70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-17f1c9b4-e145-41ea-b462-2e21ffde3d70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"IMDB_CLEANED.csv\", index = False)"
      ],
      "metadata": {
        "id": "LXRcWeMBB4QU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ilo7cB2dRuuN"
      },
      "outputs": [],
      "source": [
        "# !pip install contractions\n",
        "# import contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciBSqOqU8OGX"
      },
      "outputs": [],
      "source": [
        "# df = pd.concat([ICD_train, ICD_test, ICD_val]) # issue of duplicate indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjFZe0RIQUHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f97fc02-4d66-44dd-be25-3e24f6cab757"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azIcbSJrPqam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18e89a0-063a-4d9c-8d48-aa7744ff59dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "df.index.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TrJ7o0aQaqG"
      },
      "outputs": [],
      "source": [
        "df.reset_index(inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKHNJ3BWQekz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2cad05f-9a36-49f4-97c3-4335794434f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "df.index.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQ4dgd-JROjf"
      },
      "outputs": [],
      "source": [
        "# def filter_admission_text(notes_df) -> pd.DataFrame:\n",
        "#     \"\"\"\n",
        "#     Filter text information by section and only keep sections that are known on admission time.\n",
        "#     \"\"\"\n",
        "#     admission_sections = {\n",
        "#         \"CHIEF_COMPLAINT\": \"chief complaint:\",\n",
        "#         \"PRESENT_ILLNESS\": \"present illness:\",\n",
        "#         \"MEDICAL_HISTORY\": \"medical history:\",\n",
        "#         \"MEDICATION_ADM\": \"medications on admission:\",\n",
        "#         \"ALLERGIES\": \"allergies:\",\n",
        "#         \"PHYSICAL_EXAM\": \"physical exam:\",\n",
        "#         \"FAMILY_HISTORY\": \"family history:\",\n",
        "#         \"SOCIAL_HISTORY\": \"social history:\"\n",
        "#     }\n",
        "\n",
        "#     # replace linebreak indicators\n",
        "#     notes_df['text'] = notes_df['text'].str.replace(r\"\\n\", r\"\\\\n\")\n",
        "\n",
        "#     # extract each section by regex\n",
        "#     for key in admission_sections.keys():\n",
        "#         section = admission_sections[key]\n",
        "#         notes_df[key] = notes_df.text.str.extract(r'(?i){}(.+?)\\\\n\\\\n[^(\\\\|\\d|\\.)]+?:'\n",
        "#                                                   .format(section))\n",
        "\n",
        "#         notes_df[key] = notes_df[key].str.replace(r'\\\\n', r' ')\n",
        "#         notes_df[key] = notes_df[key].str.strip()\n",
        "#         notes_df[key] = notes_df[key].fillna(\"\")\n",
        "#         notes_df[notes_df[key].str.startswith(\"[]\")][key] = \"\"\n",
        "\n",
        "#     # filter notes with missing main information\n",
        "# #     notes_df = notes_df[(notes_df.CHIEF_COMPLAINT != \"\") | (notes_df.PRESENT_ILLNESS != \"\") |\n",
        "# #                         (notes_df.MEDICAL_HISTORY != \"\")]\n",
        "\n",
        "#     # add section headers and combine into TEXT_ADMISSION\n",
        "#     notes_df = notes_df.assign(TEXT=\"CHIEF COMPLAINT: \" + notes_df.CHIEF_COMPLAINT.astype(str)\n",
        "#                                     + '\\n\\n' +\n",
        "#                                     \"PRESENT ILLNESS: \" + notes_df.PRESENT_ILLNESS.astype(str)\n",
        "#                                     + '\\n\\n' +\n",
        "#                                     \"MEDICAL HISTORY: \" + notes_df.MEDICAL_HISTORY.astype(str)\n",
        "#                                     + '\\n\\n' +\n",
        "#                                     \"MEDICATION ON ADMISSION: \" + notes_df.MEDICATION_ADM.astype(str)\n",
        "#                                     + '\\n\\n' +\n",
        "#                                     \"ALLERGIES: \" + notes_df.ALLERGIES.astype(str)\n",
        "#                                     + '\\n\\n' +\n",
        "#                                     \"PHYSICAL EXAM: \" + notes_df.PHYSICAL_EXAM.astype(str)\n",
        "#                                     + '\\n\\n' +\n",
        "#                                     \"FAMILY HISTORY: \" + notes_df.FAMILY_HISTORY.astype(str)\n",
        "#                                     + '\\n\\n' +\n",
        "#                                     \"SOCIAL HISTORY: \" + notes_df.SOCIAL_HISTORY.astype(str))\n",
        "\n",
        "#     return notes_df\n",
        "\n",
        "# df_filtered = filter_admission_text(df)\n",
        "\n",
        "# my_stop_words = ['discharge', 'diagnosis', 'medications', 'medication', 'disposition', 'condition', 'instructions', \n",
        "#                  'status', 'secondary', 'changes', 'instruction', 'change', 'home', 'name', 'hospital', 'daily',\n",
        "#                 'hour', 'follow', 'care', 'time', 'day', 'week', 'with', 'disp', 'discharged', 'admitted', \n",
        "#                  'namepattern', 'none', 'chief', 'complaint', 'physical', 'exam', 'present', 'illness', 'family','year', 'history','admission', 'social', 'medical', 'allergies']\n",
        "\n",
        "# stemmer = WordNetLemmatizer()\n",
        "\n",
        "# def clean_string(s):\n",
        "#     # Remove all the special characters\n",
        "#     s_clean = re.sub(r'\\W', ' ', s)\n",
        "#     s_clean = re.sub('_', ' ', s)\n",
        "#     # Remove new line characters\n",
        "#     s_clean = s_clean.replace(\"\\n\", ' ')\n",
        "#     # Punctuation\n",
        "#     s_clean = re.sub(r'[^\\w\\s]', ' ', s_clean)\n",
        "#     # remove all single characters\n",
        "#     s_clean = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', s_clean)\n",
        "#     # Remove single characters from the start\n",
        "#     s_clean = re.sub(r'\\^[a-zA-Z]\\s+', ' ', s_clean) \n",
        "#     # Substituting multiple spaces with single space\n",
        "#     s_clean = re.sub(r'\\s+', ' ', s_clean, flags=re.I)\n",
        "#     # Removing prefixed 'b'\n",
        "#     s_clean = re.sub(r'^b\\s+', '', s_clean)\n",
        "#     #Removing Numbers\n",
        "#     s_clean = ''.join(i for i in s_clean if not i.isdigit())\n",
        "#     #Removing Stopwords\n",
        "#     s_clean = ' '.join([i for i in s_clean.split() if not i in all_stopwords])\n",
        "#     #Removing certain sized words\n",
        "#     s_clean = ' '.join([i for i in s_clean.split() if len(i)>3])\n",
        "#     # Contractions\n",
        "#     s_clean = contractions.fix(s_clean)\n",
        "#     # Converting to Lowercase\n",
        "#     s_clean = s_clean.lower()\n",
        "#     # Lemmatization\n",
        "#     s_clean = s_clean.split()\n",
        "#     s_clean = [stemmer.lemmatize(word) for word in s_clean]\n",
        "#     s_clean = ' '.join(s_clean)\n",
        "#     #Removing my_stop_words\n",
        "#     s_clean = ' '.join([i for i in s_clean.split() if not i in my_stop_words])\n",
        "#     return s_clean\n",
        "\n",
        "# df_filtered['TEXT_cleaned'] = [clean_string(s) for s in df_filtered['TEXT']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9O7vVR6RSY1"
      },
      "outputs": [],
      "source": [
        "# def get_top_ICD9(s):\n",
        "#   code = s.split(',')[0]\n",
        "#   return code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84BmosvQSjtu"
      },
      "outputs": [],
      "source": [
        "# df_filtered['top_icd'] = [get_top_ICD9(x) for x in df_filtered['short_codes']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMg_VvI9Sli3"
      },
      "outputs": [],
      "source": [
        "# top_classes = df_filtered['top_icd'].value_counts()[0:4].index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-bR04LhSm1H"
      },
      "outputs": [],
      "source": [
        "# filter_list = df_filtered['top_icd'].isin(top_classes)\n",
        "# df_to_predict = df_filtered[filter_list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7R0IO3aRSpn2"
      },
      "outputs": [],
      "source": [
        "# df_to_predict.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48rJ1ynbSu-W"
      },
      "outputs": [],
      "source": [
        "# df.shape, df_to_predict.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zo-ONzEr8xHF"
      },
      "outputs": [],
      "source": [
        "# df_to_predict.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klKBb-4y_Azg"
      },
      "outputs": [],
      "source": [
        "# columns_to_drop = [ col for col in df_to_predict.columns if not (col =='TEXT_cleaned' or col == 'top_icd')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqBqYf0mAZX9"
      },
      "outputs": [],
      "source": [
        "# df_to_predict.drop(columns=columns_to_drop, axis = 1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_1VireMA-jq"
      },
      "outputs": [],
      "source": [
        "# df_to_predict.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TCKC85BBBBe"
      },
      "outputs": [],
      "source": [
        "# df = df_to_predict.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoWbvGPDBDm7"
      },
      "outputs": [],
      "source": [
        "# df.top_icd.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PtfMevtBPVc"
      },
      "outputs": [],
      "source": [
        "# def get_data(df:pd.DataFrame):\n",
        "#   df.top_icd = df.top_icd.map({'414':0, '038': 1, '410':2, '424': 3})\n",
        "#   df = df.loc[df['top_icd'].isin([0, 1, 2, 3])]\n",
        "#   df['top_icd'] = df['top_icd'].astype('int64')\n",
        "#   return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBnC4jbABUxX"
      },
      "outputs": [],
      "source": [
        "# df = get_data(df)\n",
        "# df = df.iloc[:, 0:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uga-MM47jAB"
      },
      "outputs": [],
      "source": [
        "# df.top_icd.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN_dtNh3Mgmv"
      },
      "outputs": [],
      "source": [
        "# df.index.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "De2QL4jBEiWk"
      },
      "outputs": [],
      "source": [
        "# df.rename(columns = {'top_icd':'label', 'TEXT_cleaned':'text'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7N9arKLEV8J"
      },
      "outputs": [],
      "source": [
        "##do we really neeed anything like this [**Hospital6 8283**] [**9-26**]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqiKsuvgw3hG"
      },
      "outputs": [],
      "source": [
        "# df.to_csv('dataset_cleaned_sean.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "euzZ3WljbkKl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c54596d6-ee67-43ac-f9cf-c5f01d90f089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index                                               text  label\n",
              "0      0  one review ha mention watch 1 Oz episod youll ...      1\n",
              "1      1  wonder littl product film techniqu veri unassu...      1\n",
              "2      2  thought thi wa wonder way spend time hot summe...      1\n",
              "3      3  basic famili littl boy jake think zombi hi clo...      0\n",
              "4      4  petter mattei love time money visual stun film...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-229e9c18-e203-4b0d-9540-582eda991adf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>one review ha mention watch 1 Oz episod youll ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>wonder littl product film techniqu veri unassu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>thought thi wa wonder way spend time hot summe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>basic famili littl boy jake think zombi hi clo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>petter mattei love time money visual stun film...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-229e9c18-e203-4b0d-9540-582eda991adf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-229e9c18-e203-4b0d-9540-582eda991adf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-229e9c18-e203-4b0d-9540-582eda991adf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1olZQuqjDB2u"
      },
      "source": [
        "Chucking our long clinical texts before apply BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETo294z8-fUL"
      },
      "source": [
        "## Chunking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en13O4VTDA36"
      },
      "outputs": [],
      "source": [
        "def get_split(text1):\n",
        "  l_total = []\n",
        "  l_partial = []\n",
        "  if len(text1.split())//150 >0:\n",
        "    n = len(text1.split())//150\n",
        "  else: \n",
        "    n = 1\n",
        "  for w in range(n):\n",
        "    if w == 0:\n",
        "      l_partial = text1.split()[:200]\n",
        "      l_total.append(\" \".join(l_partial))\n",
        "    else:\n",
        "      l_partial = text1.split()[w*150:w*150 + 200]\n",
        "      l_total.append(\" \".join(l_partial))\n",
        "  return l_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1fkcJF-AlJg"
      },
      "outputs": [],
      "source": [
        "def chunk_text(df:pd.DataFrame, column_name):\n",
        "  df['text_split'] = df[column_name].apply(get_split)\n",
        "\n",
        "  train_l = []\n",
        "  label_l = []\n",
        "  index_l = []\n",
        "  \n",
        "  for idx,row in df.iterrows():\n",
        "    for l in row['text_split']:\n",
        "      train_l.append(l)\n",
        "      label_l.append(row['label'])\n",
        "      index_l.append(idx)\n",
        "  df_temp = pd.DataFrame({'TEXT':train_l, 'label':label_l})\n",
        "  print(\"Old Shape Before Chunking:\", df.shape, \"\\n\", \"New Shape After Chunking:\", df_temp.shape)\n",
        "  return df_temp"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_temp = pd.read_csv(\"/content/dataset_cleaned_sean.csv\")"
      ],
      "metadata": {
        "id": "ozsSNl7rur0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_temp.head()"
      ],
      "metadata": {
        "id": "Eh-5Cqr_vCZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp = df.copy()"
      ],
      "metadata": {
        "id": "2qXU5WI3CI92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp['Length'] = df_temp.text.apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "p_cf4p5zxVcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp.label[6536]"
      ],
      "metadata": {
        "id": "q1YTEfeN07TC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e544c1a6-de1d-47dd-cbf4-2d274532b384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_temp.text[6536].split())"
      ],
      "metadata": {
        "id": "St5Z8pcD0Etg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8541daa5-0400-4dd8-b643-2dd595271d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp.iloc[6536: 6537, :]"
      ],
      "metadata": {
        "id": "uxeytYNzzh_9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "b56ef9de-3ca0-4ba3-c4de-2e239936e382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      index                                               text  label  Length\n",
              "6536   6536  thi show wa exhaust watch onli two number drow...      1     149"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf965067-6eca-4426-8925-2d9fb14af680\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6536</th>\n",
              "      <td>6536</td>\n",
              "      <td>thi show wa exhaust watch onli two number drow...</td>\n",
              "      <td>1</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf965067-6eca-4426-8925-2d9fb14af680')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cf965067-6eca-4426-8925-2d9fb14af680 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cf965067-6eca-4426-8925-2d9fb14af680');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = df_temp.Length.argmax()\n",
        "index"
      ],
      "metadata": {
        "id": "Tn9Zj2eUxoz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26be78a0-25e4-4437-e6c5-bc58de02ee59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31481"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = chunk_text(df, \"text\")"
      ],
      "metadata": {
        "id": "PSp_nxrdg9YE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "473d6fd7-6fcf-4f88-c13e-814287586d8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Old Shape Before Chunking: (50000, 4) \n",
            " New Shape After Chunking: (54147, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"IMDB_chunked.csv\", index = False)"
      ],
      "metadata": {
        "id": "WwdPcWKUhYhJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "AUrU-y_UhF0U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "de70d09d-c9c0-4b01-8ad6-4c6b95b7db60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                TEXT  label\n",
              "0  one review ha mention watch 1 Oz episod youll ...      1\n",
              "1  wonder littl product film techniqu veri unassu...      1\n",
              "2  thought thi wa wonder way spend time hot summe...      1\n",
              "3  basic famili littl boy jake think zombi hi clo...      0\n",
              "4  petter mattei love time money visual stun film...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ba09e26-6c4c-4fb9-bec3-4f50c446405c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXT</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>one review ha mention watch 1 Oz episod youll ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>wonder littl product film techniqu veri unassu...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>thought thi wa wonder way spend time hot summe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>basic famili littl boy jake think zombi hi clo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>petter mattei love time money visual stun film...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ba09e26-6c4c-4fb9-bec3-4f50c446405c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ba09e26-6c4c-4fb9-bec3-4f50c446405c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ba09e26-6c4c-4fb9-bec3-4f50c446405c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hF6mx6UCjfz",
        "outputId": "85967eb7-aa0d-4f11-9414-7693dfd73db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54147, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.label.value_counts()"
      ],
      "metadata": {
        "id": "9KEmK-Ybhr3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c97ce1a8-41bc-438d-9204-e0326a214d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    27288\n",
              "0    26859\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 0    3502\n",
        "- 1    3184\n",
        "- 2    3175\n",
        "- 3    1676"
      ],
      "metadata": {
        "id": "9TTUp7qP1mja"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEimxF-XvMK1"
      },
      "source": [
        "#### 2.3 Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNNvGLZA2CQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2040261-72dd-46e5-8aa8-00f40843beec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54147, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tVgs_i1LPUvW"
      },
      "outputs": [],
      "source": [
        "train, test = train_test_split(df, test_size = 0.3, random_state=42, stratify=df.label.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuNmR3TjCfQq"
      },
      "outputs": [],
      "source": [
        "# train = chunk_text(train, 'TEXT')\n",
        "# test = chunk_text(test, 'TEXT')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTijZig1MBA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb1790a9-62bb-4439-a7b5-c234eb6b115f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37902, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idvB-iQhMDjf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "94c1b6bf-7480-46e2-9c5f-f34521b45c25"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    TEXT  label\n",
              "12775  thi film exactli titl describesan attempt get ...      1\n",
              "42404  snake train start mexican coupl brujo AJ castr...      0\n",
              "51615  still favoriteth movi take page alien book del...      1\n",
              "34850  thi engross woman drama men enjoy plot follow ...      1\n",
              "32489  tune hi americana drum along mohawk john ford ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47f9a981-ced7-4405-b5b9-2780ba873f77\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXT</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12775</th>\n",
              "      <td>thi film exactli titl describesan attempt get ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42404</th>\n",
              "      <td>snake train start mexican coupl brujo AJ castr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51615</th>\n",
              "      <td>still favoriteth movi take page alien book del...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34850</th>\n",
              "      <td>thi engross woman drama men enjoy plot follow ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32489</th>\n",
              "      <td>tune hi americana drum along mohawk john ford ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47f9a981-ced7-4405-b5b9-2780ba873f77')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47f9a981-ced7-4405-b5b9-2780ba873f77 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47f9a981-ced7-4405-b5b9-2780ba873f77');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ktJPZF1Si88"
      },
      "outputs": [],
      "source": [
        "train_texts = train.TEXT\n",
        "train_labels = train.label\n",
        "test_texts = test.TEXT\n",
        "test_labels = test.label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_texts[10].split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K2eMlJMCx6S",
        "outputId": "fdfe45f2-4687-45ea-ac2e-d16158213153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdKb2Qv7rxmi"
      },
      "source": [
        "#3. ***Building Model***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sl8RVsmuLIK"
      },
      "source": [
        "## 3.1 Text Preprocessing For BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEF2LjsGsh0H"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1x_Jn-sEBFf"
      },
      "source": [
        "[Read Feature Extraction Here](https://huggingface.co/transformers/v3.0.2/main_classes/pipelines.html#:~:text=Feature%20extraction%20pipeline%20using%20Model%20head.%20This%20pipeline%20extracts%20the%20hidden%20states%20from%20the%20base%20transformer%2C%20which%20can%20be%20used%20as%20features%20in%20downstream%20tasks.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wlEiZ3cNt19m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "387c4012-f88b-477a-dcd0-9137615c37c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sequence length: 387\n"
          ]
        }
      ],
      "source": [
        "max_len = 0\n",
        "\n",
        "for seq in train_texts:\n",
        "    # Tokenize the text by BERT tokenizer\n",
        "    input_ids = tokenizerBERT.encode(seq, add_special_tokens=True)\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sequence length:', max_len) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nQaHIKc_zZY"
      },
      "outputs": [],
      "source": [
        "# Tokenize all of the sequences and map the tokens to thier IDs.\n",
        "input_ids_train = []\n",
        "attention_masks_train = []\n",
        "\n",
        "# For every sequences\n",
        "for seq in train_texts:\n",
        "    encoded_dict = tokenizerBERT.encode_plus(\n",
        "                        seq,                             # Sequence to encode\n",
        "                        add_special_tokens = True,       # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,                # 128 or 512 ????\n",
        "                        padding = 'max_length',          # Pad and truncate\n",
        "                        truncation=True,                 # Truncate the seq\n",
        "                        return_attention_mask = True,    # Construct attn. masks\n",
        "                        return_tensors = 'pt',           # Return pytorch tensors\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sequences to the list    \n",
        "    input_ids_train.append(encoded_dict['input_ids'])\n",
        "\n",
        "    '''\n",
        "    The \"Attention Mask\" is simply an array of 1s and 0s \n",
        "    indicating which tokens are padding and which aren't. \n",
        "    This mask tells the \"Self-Attention\" mechanism in BERT \n",
        "    not to incorporate these PAD tokens into its interpretation \n",
        "    of the sentence.\n",
        "    1 indicates a value that should be attended to, while 0 indicates a padded value.\n",
        "    '''\n",
        "    attention_masks_train.append(encoded_dict['attention_mask']) \n",
        "    \n",
        "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
        "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
        "train_label = torch.tensor(train_labels.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luDb1WT1D3QQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a27ebd-7da3-4eef-db5e-8cb72e4c033e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 30321\n",
            "Validation set size: 7581\n"
          ]
        }
      ],
      "source": [
        "# Change to TensorDataset and Split to train and validation sets (80-20)\n",
        "dataset = TensorDataset(input_ids_train, attention_masks_train, train_label) \n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('Training set size:', format(train_size))\n",
        "print('Validation set size:', format(val_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH5J3heLinDV"
      },
      "source": [
        "## 3.2 Building Dataset and BERT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5KLuLvkO0rw"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = batch_size)\n",
        "validation_dataloader = DataLoader(val_dataset, sampler = SequentialSampler(val_dataset), batch_size = batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrZ1H95fU5Bx"
      },
      "outputs": [],
      "source": [
        "epochs = 2   # recomended 2-4 by BERT model's authors  # on epoch = 2 and chunking is on then we get balanced accuracy of 71% on test\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtLA6RqpWnMX"
      },
      "outputs": [],
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGKWDmb4jBxL"
      },
      "source": [
        "# 4. ***Model Training***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcBovEzd49cw"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbD1w4VUFaES",
        "outputId": "196db3fe-1fd0-49e6-ee01-5396a7b515bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FW0ZrudNfQbG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9dc7f3-1c77-4730-fcbe-411f637a040b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 2\n",
            "  Batch   100  of  1,896.    Elapsed: 0:02:21.\n",
            "  Batch   200  of  1,896.    Elapsed: 0:04:40.\n",
            "  Batch   300  of  1,896.    Elapsed: 0:07:00.\n",
            "  Batch   400  of  1,896.    Elapsed: 0:09:19.\n",
            "  Batch   500  of  1,896.    Elapsed: 0:11:38.\n",
            "  Batch   600  of  1,896.    Elapsed: 0:13:58.\n",
            "  Batch   700  of  1,896.    Elapsed: 0:16:17.\n",
            "  Batch   800  of  1,896.    Elapsed: 0:18:37.\n",
            "  Batch   900  of  1,896.    Elapsed: 0:20:56.\n",
            "  Batch 1,000  of  1,896.    Elapsed: 0:23:16.\n",
            "  Batch 1,100  of  1,896.    Elapsed: 0:25:35.\n",
            "  Batch 1,200  of  1,896.    Elapsed: 0:27:55.\n",
            "  Batch 1,300  of  1,896.    Elapsed: 0:30:15.\n",
            "  Batch 1,400  of  1,896.    Elapsed: 0:32:34.\n",
            "  Batch 1,500  of  1,896.    Elapsed: 0:34:53.\n",
            "  Batch 1,600  of  1,896.    Elapsed: 0:37:13.\n",
            "  Batch 1,700  of  1,896.    Elapsed: 0:39:32.\n",
            "  Batch 1,800  of  1,896.    Elapsed: 0:41:52.\n",
            "\n",
            "\n",
            " Average training loss: 0.36\n",
            " Training epoch took: 0:44:04\n",
            "\n",
            "\n",
            "Validation\n",
            "  Accuracy: 0.88\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:03:58\n",
            "Epoch 2 / 2\n",
            "  Batch   100  of  1,896.    Elapsed: 0:02:20.\n",
            "  Batch   200  of  1,896.    Elapsed: 0:04:39.\n",
            "  Batch   300  of  1,896.    Elapsed: 0:06:58.\n",
            "  Batch   400  of  1,896.    Elapsed: 0:09:18.\n",
            "  Batch   500  of  1,896.    Elapsed: 0:11:37.\n",
            "  Batch   600  of  1,896.    Elapsed: 0:13:57.\n",
            "  Batch   700  of  1,896.    Elapsed: 0:16:16.\n",
            "  Batch   800  of  1,896.    Elapsed: 0:18:36.\n",
            "  Batch   900  of  1,896.    Elapsed: 0:20:56.\n",
            "  Batch 1,000  of  1,896.    Elapsed: 0:23:15.\n",
            "  Batch 1,100  of  1,896.    Elapsed: 0:25:35.\n",
            "  Batch 1,200  of  1,896.    Elapsed: 0:27:54.\n",
            "  Batch 1,300  of  1,896.    Elapsed: 0:30:15.\n",
            "  Batch 1,400  of  1,896.    Elapsed: 0:32:35.\n",
            "  Batch 1,500  of  1,896.    Elapsed: 0:34:56.\n",
            "  Batch 1,600  of  1,896.    Elapsed: 0:37:17.\n",
            "  Batch 1,700  of  1,896.    Elapsed: 0:39:38.\n",
            "  Batch 1,800  of  1,896.    Elapsed: 0:41:59.\n",
            "\n",
            "\n",
            " Average training loss: 0.21\n",
            " Training epoch took: 0:44:13\n",
            "\n",
            "\n",
            "Validation\n",
            "  Accuracy: 0.89\n",
            "  Validation Loss: 0.00\n",
            "  Validation took: 0:04:02\n",
            "\n",
            "\n",
            "Training complete!\n",
            "Total training took 1:36:18 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "# Training start\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# use training_status to store loss values, accuracy and elapsed time\n",
        "training_status = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    #-------------------Training-----------------------#\n",
        "    print('Epoch {:} / {:}'.format(epoch_i + 1, epochs))\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "\n",
        "      if step % 100 == 0 and not step == 0:\n",
        "\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "      \n",
        "\n",
        "      model.zero_grad()       \n",
        "      loss, logits, output_hidden_state_train = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels,\n",
        "                             return_dict = False)\n",
        "        \n",
        "      total_train_loss += loss.item()\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)             \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\" Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\" Training epoch took: {:}\".format(training_time))\n",
        "         \n",
        "    # ------------------Validation--------------------#\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"Validation\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():        \n",
        "            (loss, logits, output_hidden_state_val) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels,\n",
        "                                   return_dict = False)\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    training_status.append(\n",
        "        {\n",
        "            'Epochs': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Validation Loss': avg_val_loss,\n",
        "            'Validation Accuracy.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY3dQ311j2W1"
      },
      "source": [
        "## 4.1 Building Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILNaOPLrkpTb"
      },
      "outputs": [],
      "source": [
        "# Tokenize all of the sequences and map the tokens to thier IDs.\n",
        "input_ids_test = []\n",
        "attention_masks_test = []\n",
        "\n",
        "# For every sequences\n",
        "for seq in test_texts:\n",
        "    encoded_dict = tokenizerBERT.encode_plus(\n",
        "                        seq,                             # Sequence to encode\n",
        "                        add_special_tokens = True,       # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,               # 128 or 512 ???\n",
        "                        padding = 'max_length',          # Pad and truncate\n",
        "                        truncation=True,                 # Truncate the seq\n",
        "                        return_attention_mask = True,    # Construct attn. masks\n",
        "                        return_tensors = 'pt',           # Return pytorch tensors\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sequences to the list    \n",
        "    input_ids_test.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask\n",
        "    attention_masks_test.append(encoded_dict['attention_mask'])\n",
        "    \n",
        "input_ids_test = torch.cat(input_ids_test, dim=0)\n",
        "attention_masks_test = torch.cat(attention_masks_test, dim=0)\n",
        "test_labels = torch.tensor(test_labels.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYbVzRM1wVmo"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "prediction_data = TensorDataset(input_ids_test, attention_masks_test, test_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(prediction_dataloader), len(prediction_data), len(prediction_sampler)"
      ],
      "metadata": {
        "id": "8ei3Yyf0O_x6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c203955-7d38-443d-f40e-e29bbca61b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1016, 16245, 16245)"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE6BAy-Wj-YO"
      },
      "source": [
        "# 4.2 Evaluating Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTTlRUcYxA16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d729560e-b98b-45c4-acae-85d16542b537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 16,245 test sentences\n"
          ]
        }
      ],
      "source": [
        "print('Predicting labels for {:,} test sentences'.format(len(input_ids_test)))\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()    \n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohx_YiDexPfP"
      },
      "outputs": [],
      "source": [
        "true_labels_array, result_label, result_prob, result_logits = [], [], [], []\n",
        "for j in range(len(true_labels)):\n",
        "    for i in range(len(true_labels[j])):\n",
        "        true_labels_array.append(true_labels[j][i])\n",
        "\n",
        "\n",
        "for j in range(len(predictions)):\n",
        "    for i in range(len(predictions[j])):      \n",
        "        index, value = max(enumerate(predictions[j][i]), key=operator.itemgetter(1))\n",
        "        result_label.append(index)\n",
        "        result_prob.append(value)\n",
        "        result_logits.append(predictions[j][i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toITmhA5kJZu"
      },
      "source": [
        "## 4.3 Model Performance: Base BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LKUKQ7g8qIL"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5mszxiobyYN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2b9Yh8_bvy2"
      },
      "outputs": [],
      "source": [
        "def confusion_plot(cm):\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax, cmap=\"Blues\"); #annot=True to annotate cells\n",
        "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels') \n",
        "    ax.set_title('Confusion Matrix')\n",
        "    labels = ['Chronic Heart', 'Sepsis','Heart Attack','Endocardium']\n",
        "    ax.xaxis.set_ticklabels(labels); ax.yaxis.set_ticklabels(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dIB8gXdxft8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "ecbd4b6d-27df-4b04-ad89-2c1d20bf415f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy             :  0.8936903662665435\n",
            "Precision            :  0.8937626894533164\n",
            "Recall               :  0.8937525903487731\n",
            "F1                   :  0.8936903082574713\n",
            "Balanced Accuracy    :  0.8937525903487731\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.89      8058\n",
            "           1       0.90      0.89      0.89      8187\n",
            "\n",
            "    accuracy                           0.89     16245\n",
            "   macro avg       0.89      0.89      0.89     16245\n",
            "weighted avg       0.89      0.89      0.89     16245\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "target_names = ['0','1']\n",
        "\n",
        "print(\"Accuracy             : \", accuracy_score(test_labels, result_label))\n",
        "print(\"Precision            : \", precision_score(test_labels, result_label, average=\"macro\"))\n",
        "print(\"Recall               : \", recall_score(test_labels, result_label, average='macro'))\n",
        "print(\"F1                   : \", f1_score(test_labels, result_label, average=\"macro\"))\n",
        "print('Balanced Accuracy    : ', balanced_accuracy_score(test_labels, result_label))\n",
        "print(\"\\n\")\n",
        "print(classification_report(true_labels_array, result_label, target_names=target_names))\n",
        "\n",
        "cmt = metrics.confusion_matrix(test_labels, result_label)\n",
        "confusion_plot(cmt)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Save Fine tuned model"
      ],
      "metadata": {
        "id": "8zRiNpyVzgM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "from pandas.core.common import SettingWithCopyWarning\n",
        "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
      ],
      "metadata": {
        "id": "JpcmvvVYeKGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)"
      ],
      "metadata": {
        "id": "YE63KkNcrQK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt "
      ],
      "metadata": {
        "id": "Ns_EMtCxc7iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_model = '/content/drive/MyDrive/AI Projects and Dataset/Health ML/bert_fined_tune_chunked_IMDB.pth'"
      ],
      "metadata": {
        "id": "2lvJEzKS8ztg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save\n",
        "def save(model, optimizer):\n",
        "    # save\n",
        "    torch.save({\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict()\n",
        "    }, output_model)\n",
        "\n",
        "save(model, optimizer)\n"
      ],
      "metadata": {
        "id": "Ku6Gpp9HziIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTWzuM2L5dAc",
        "outputId": "efc85fcd-1f55-4265-cb93-d1369e184490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(output_model, map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "metadata": {
        "id": "yWQEvX-ZZx_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/AI Projects and Dataset/Health ML/dataframe_cleaned_chunked.csv\")"
      ],
      "metadata": {
        "id": "K3nShikkOS9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = df.TEXT\n",
        "train_labels = df.label"
      ],
      "metadata": {
        "id": "hhH1zwVjkhAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sequences and map the tokens to thier IDs.\n",
        "input_ids_train = []\n",
        "attention_masks_train = []\n",
        "\n",
        "# For every sequences\n",
        "for seq in train_texts:\n",
        "    encoded_dict = tokenizerBERT.encode_plus(\n",
        "                        seq,                             # Sequence to encode\n",
        "                        add_special_tokens = True,       # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 256,                # 128 or 512 ????\n",
        "                        padding = 'max_length',          # Pad and truncate\n",
        "                        truncation=True,                 # Truncate the seq\n",
        "                        return_attention_mask = True,    # Construct attn. masks\n",
        "                        return_tensors = 'pt',           # Return pytorch tensors\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sequences to the list    \n",
        "    input_ids_train.append(encoded_dict['input_ids'])\n",
        "\n",
        "    '''\n",
        "    The \"Attention Mask\" is simply an array of 1s and 0s \n",
        "    indicating which tokens are padding and which aren't. \n",
        "    This mask tells the \"Self-Attention\" mechanism in BERT \n",
        "    not to incorporate these PAD tokens into its interpretation \n",
        "    of the sentence.\n",
        "    1 indicates a value that should be attended to, while 0 indicates a padded value.\n",
        "    '''\n",
        "    attention_masks_train.append(encoded_dict['attention_mask']) \n",
        "    \n",
        "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
        "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
        "train_label = torch.tensor(train_labels.values)"
      ],
      "metadata": {
        "id": "Rk02C5aUkruN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_ids_full, attention_masks_full, train_label = get_encodings(TEXTS, LABELS)"
      ],
      "metadata": {
        "id": "sKzIYz2gmt6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "prediction_data = TensorDataset(input_ids_train, attention_masks_train, train_label)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "WFC30_LLyIVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    batch = tuple(t.to('cpu') for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "    \n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()    \n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)"
      ],
      "metadata": {
        "id": "8Lnwid5Ys9Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "d_XJ6ghPA3OG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Fine Tuning BERT [MAIN]",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}