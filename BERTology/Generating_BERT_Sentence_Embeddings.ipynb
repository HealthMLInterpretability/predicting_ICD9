{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating BERT Sentence Embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- Notebook to generate sentence embeddings using fine tuned BERT\n",
        "- approach 1. adding last four layers of BERT (Currently being used)\n",
        "- approach 2. concatenate last four layers of BERT and take mean of these layers\n"
      ],
      "metadata": {
        "id": "idcqH5KuNTIV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8O8GXlRJzX3",
        "outputId": "21429730-f208-41d1-8df4-480635555272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 32.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 36.6 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 31.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "# pip install tensorflow-text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import (BertForSequenceClassification, BertTokenizer, AdamW, BertConfig, get_linear_schedule_with_warmup)\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn import preprocessing\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "from pandas.core.common import SettingWithCopyWarning\n",
        "import operator\n",
        "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
      ],
      "metadata": {
        "id": "KAOiph77J5Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():        \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('CPU is exist.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7eVM79oKFU6",
        "outputId": "793f951a-3aa7-4d6c-852b-deca0451dc06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pWJbmDeW7GHZ",
        "outputId": "082857a9-4220-4290-eb14-4337c4044463",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") # 'bert-base-uncased' original"
      ],
      "metadata": {
        "id": "nbluzqpiKTZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 4,                 \n",
        "    output_attentions = False, \n",
        "    output_hidden_states = True,  # originally False,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPnfWARlKW4V",
        "outputId": "e8ba6b36-2a11-4773-de47-9a186573b26e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device) # model to GPU!"
      ],
      "metadata": {
        "id": "zZIef8b4AUM6",
        "outputId": "7b678ea6-22c8-42e9-fcd8-8b70c78cc747",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(model.parameters(),lr = 2e-5, eps = 1e-8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHYAtKs0KZxr",
        "outputId": "01a43f84-2f4b-420c-eb0d-dacde3c54aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Copy of dataframe_cleaned_chunked.csv\")"
      ],
      "metadata": {
        "id": "5fh789hyKcLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Uh7u_ZSKj8K",
        "outputId": "7b28b9e4-5cad-4c7e-c632-924443f146b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12008, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    map_location=lambda storage, loc: storage.cuda()\n",
        "else:\n",
        "    map_location='cpu'"
      ],
      "metadata": {
        "id": "W_iLt8lP8hpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_model = '/content/drive/MyDrive/Copy of bert_fined_tune_chunked.pth'  ## PATH FOR SAVED FINE TUNED BERT MODEL"
      ],
      "metadata": {
        "id": "UXK8H_SWKqL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(output_model, map_location=map_location)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.to(device)\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
      ],
      "metadata": {
        "id": "FrjiOZVtKu1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "Tz9VU0AuAymq",
        "outputId": "92b02a65-2f67-4bf3-db77-d942cf3d88e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "z59Q0POWAoJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df.TEXT\n",
        "labels = df.label"
      ],
      "metadata": {
        "id": "JzhBUeCOKxRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sequences and map the tokens to thier IDs.\n",
        "input_ids_train = []\n",
        "attention_masks_train = []\n",
        "\n",
        "# For every sequences\n",
        "for seq in texts:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        seq,                             \n",
        "                        add_special_tokens = True,      \n",
        "                        max_length = 200,              \n",
        "                        padding = 'max_length',         \n",
        "                        truncation=True,                \n",
        "                        return_attention_mask = True,  \n",
        "                        return_tensors = 'pt',          \n",
        "                   )\n",
        "    \n",
        "    input_ids_train.append(encoded_dict['input_ids'])\n",
        "    attention_masks_train.append(encoded_dict['attention_mask']) \n",
        "    \n",
        "input_ids_train = torch.cat(input_ids_train, dim=0)\n",
        "attention_masks_train = torch.cat(attention_masks_train, dim=0)\n",
        "train_label = torch.tensor(labels.values)"
      ],
      "metadata": {
        "id": "kxXRwKUZsL7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_train.shape, attention_masks_train.shape, train_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBbUqgVPJHLo",
        "outputId": "c073fbe0-66b0-45c3-f081-bc816be3dbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([12008, 200]), torch.Size([12008, 200]), torch.Size([12008]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(input_ids_train, attention_masks_train, train_label) \n",
        "prediction_sampler = SequentialSampler(dataset)\n",
        "prediction_dataloader = DataLoader(dataset, sampler=prediction_sampler, batch_size=1)"
      ],
      "metadata": {
        "id": "fErAq8cjRbuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(prediction_dataloader), len(prediction_sampler), len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0Z2jZL4Rhjw",
        "outputId": "cab34e8f-a0a2-48e5-b216-f29e09e0cab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12008, 12008, 12008)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(prediction_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzPJb4xPid7B",
        "outputId": "d628ca6b-5d2e-4f75-bd3e-fec462e398bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataloader.DataLoader"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_dict_temp = tokenizer.encode_plus(\n",
        "                    df.TEXT[0],                             \n",
        "                    add_special_tokens = True,      \n",
        "                    max_length = 200,              \n",
        "                    padding = 'max_length',         \n",
        "                    truncation=True,                \n",
        "                    return_attention_mask = True,  \n",
        "                    return_tensors = 'pt',          \n",
        "                )"
      ],
      "metadata": {
        "id": "WHaUOul_2sBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_dict_temp = encoded_dict_temp.to(device)"
      ],
      "metadata": {
        "id": "DcFkaXdb28mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "        outputs = model(encoded_dict_temp['input_ids'], token_type_ids=None, attention_mask=encoded_dict_temp['attention_mask'])"
      ],
      "metadata": {
        "id": "LHEYl16B21Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_states = outputs['hidden_states']"
      ],
      "metadata": {
        "id": "_eiIpfWs3Cl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence Embeddings From BERT"
      ],
      "metadata": {
        "id": "y5dVx9wKg5dJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "oWRQCqnx7KRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Predicting labels for {:,} test sentences'.format(len(input_ids_train)))\n",
        "\n",
        "predictions , true_labels, embeddings = [], [], []\n",
        "\n",
        "for batch in prediction_dataloader:\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "    hidden_states = outputs['hidden_states']\n",
        "    last_four_layers = hidden_states[-4:]\n",
        "    last_four_layers = torch.sum(last_four_layers[-4:], dim=0)\n",
        "    # last_four_layers = torch.cat((last_four_layers[-1], last_four_layers[-2], last_four_layers[-3], last_four_layers[-4]), dim=0)\n",
        "    # last_four_layers = last_four_layers.mean(dim=(0,1)).detach().cpu().numpy().tolist()\n",
        "    last_four_layers = torch.mean(last_four_layers, dim=0)\n",
        "    sentence_embedding_last4 = last_four_layers\n",
        "    embeddings.append(sentence_embedding_last4)\n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()    \n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)"
      ],
      "metadata": {
        "id": "6bL9geRztReP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b928a7e4-fcf6-49bd-df54-b29c20c88419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 12,008 test sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyjMUrI18XDV",
        "outputId": "65f9120a-1d42-49b9-90ca-db7814c6786c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12008"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = labels.tolist()"
      ],
      "metadata": {
        "id": "MzsqSVb7VfB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(true_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdJDF0MMVxam",
        "outputId": "da2659ce-7edd-4360-e1ef-2b945113b42e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12008"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import balanced_accuracy_score"
      ],
      "metadata": {
        "id": "AobPQgLrWKN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_label, result_prob, result_logits = [], [], []\n",
        "\n",
        "for j in range(len(predictions)):\n",
        "    for i in range(len(predictions[j])):      \n",
        "        index, value = max(enumerate(predictions[j][i]), key=operator.itemgetter(1))\n",
        "        result_label.append(index)\n",
        "        result_prob.append(value)\n",
        "        result_logits.append(predictions[j][i])"
      ],
      "metadata": {
        "id": "BJtTtVkmVa7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['embeddings'] = embeddings"
      ],
      "metadata": {
        "id": "kGboDxD0WOAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "FP3DRNicWUlv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6fdca754-46c7-4b5b-f313-91c2e9f0a812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                TEXT  label  \\\n",
              "0  this white male known murmur childhood post in...      3   \n",
              "1  substernal chest pain male smoker presented ex...      2   \n",
              "2  chest pain female dmii presented transferred c...      0   \n",
              "3  presented respiratory distress outside transfe...      2   \n",
              "4  patient male previous coronary artery disease ...      2   \n",
              "\n",
              "                                          embeddings  \n",
              "0  [-0.15449006855487823, 0.11092683672904968, 0....  \n",
              "1  [-0.129572793841362, -0.2990940511226654, 0.77...  \n",
              "2  [-0.19728921353816986, -0.25027644634246826, 0...  \n",
              "3  [-0.1861894130706787, -0.40119650959968567, 0....  \n",
              "4  [-0.17907600104808807, -0.14241871237754822, 0...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b42b25d8-9813-4b43-b312-a973fa51e665\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TEXT</th>\n",
              "      <th>label</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>this white male known murmur childhood post in...</td>\n",
              "      <td>3</td>\n",
              "      <td>[-0.15449006855487823, 0.11092683672904968, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>substernal chest pain male smoker presented ex...</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.129572793841362, -0.2990940511226654, 0.77...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chest pain female dmii presented transferred c...</td>\n",
              "      <td>0</td>\n",
              "      <td>[-0.19728921353816986, -0.25027644634246826, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>presented respiratory distress outside transfe...</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.1861894130706787, -0.40119650959968567, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>patient male previous coronary artery disease ...</td>\n",
              "      <td>2</td>\n",
              "      <td>[-0.17907600104808807, -0.14241871237754822, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b42b25d8-9813-4b43-b312-a973fa51e665')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b42b25d8-9813-4b43-b312-a973fa51e665 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b42b25d8-9813-4b43-b312-a973fa51e665');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"Embeddings_last_4_layers_mean.csv\", index = False)"
      ],
      "metadata": {
        "id": "r47LIMNpWYHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_numerical_dataset(features, df_kms:pd.DataFrame, isCategorical= False, num_classes = 4):\n",
        "  columns = np.arange(0,features)\n",
        "  df_temp = df_kms.copy()\n",
        "  for x in range(0,df_temp.shape[0]):\n",
        "    df_temp.embeddings[x] = df_temp.embeddings[x]\n",
        "  print(\"Input dataframe shape:\", df_temp.shape)\n",
        "  df_split = pd.DataFrame(df_temp[\"embeddings\"].to_list(), columns=columns)\n",
        "  df_split.iloc[:1, :]\n",
        "  df_split['label'] = df_kms.label\n",
        "  print(\"Output dataframe shape:\", df_split.shape)\n",
        "  return df_split"
      ],
      "metadata": {
        "id": "0BroCSa6b1Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_kms = build_numerical_dataset(768, df, isCategorical= False, num_classes = 4)"
      ],
      "metadata": {
        "id": "uQpPOgNab1Pr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2172e75b-9d5d-4aa0-abc7-bb2e0231573a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input dataframe shape: (12008, 3)\n",
            "Output dataframe shape: (12008, 769)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_kms.to_csv(\"BERT_Embeddings_Dataset_last_four_layers_mean.csv\", index = False)"
      ],
      "metadata": {
        "id": "XgVjlTM_eA1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans"
      ],
      "metadata": {
        "id": "kEiPZC6CeMZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_kms_copy = df_kms.copy()"
      ],
      "metadata": {
        "id": "8a2ARnoieVv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df_kms_copy.label"
      ],
      "metadata": {
        "id": "nSVV9U9rebUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_kms_copy.drop(columns={'label'}, inplace = True)"
      ],
      "metadata": {
        "id": "jWua32rgeuN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_kms_copy\n",
        "print(Y.shape, X.shape)"
      ],
      "metadata": {
        "id": "P1mU8yYGewjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e848ca8-c667-4c74-e3b1-585c1c3183ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12008,) (12008, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=4, random_state=0)\n",
        "kmeans.fit(X)"
      ],
      "metadata": {
        "id": "0AvKZLGNec1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727bd70b-1fec-4846-9815-331c48770043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=4, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = kmeans.labels_"
      ],
      "metadata": {
        "id": "_qL9UCdreehB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df_kms.label"
      ],
      "metadata": {
        "id": "aXKLJxXYe1VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_labels = sum(Y == pred)\n",
        "print(\"Result: %d out of %d samples were correctly labeled.\" % (correct_labels, len(Y)))\n",
        "print('Accuracy score:', np.round((correct_labels/float(len(Y)))*100, 2),\" %\")"
      ],
      "metadata": {
        "id": "SRIIq5F6e208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5caaa0cb-276a-4397-c3ec-8eeb545a6ce6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: 5098 out of 12008 samples were correctly labeled.\n",
            "Accuracy score: 42.46  %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cnn(df:pd.DataFrame, DataName: str, EPOCHS:int):\n",
        "  print(DataName, \":\", df.shape)\n",
        "  Y = df.label\n",
        "  X = df.drop(columns=['label'])\n",
        "  Y = to_categorical(Y, 4)\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.3)\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(512, 4, activation='relu', input_shape = (X_train.shape[1],1)))\n",
        "  model.add(BatchNormalization()) \n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  # model.add(Dropout(0.5)) \n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(MaxPooling1D(2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(4, activation='softmax'))\n",
        "  model.compile(loss=\"categorical_crossentropy\", optimizer = 'adam', metrics=[\"accuracy\"])\n",
        "\n",
        "  history = model.fit(X_train, Y_train,validation_split=0.25, epochs = EPOCHS, batch_size=32, shuffle=True, verbose=1)  \n",
        "  predictions = model.predict(X_test)\n",
        "  Y_pred = predictions.argmax(axis=1)\n",
        "  Y_test_max = Y_test.argmax(axis=1)\n",
        "  auc = roc_auc_score(Y_test_max, predictions, multi_class='ovr', average='macro')\n",
        "  accuracy = np.round(accuracy_score(Y_test_max, Y_pred)*100,4)\n",
        "  bal_acc = np.round(balanced_accuracy_score(Y_test_max, Y_pred)*100,4)\n",
        "  recall = np.round(recall_score(Y_test_max, Y_pred, average='micro')*100,4)\n",
        "  f1_weighted = np.round(f1_score(Y_test_max, Y_pred, average='weighted')*100,4)\n",
        "  f1_average = np.round(f1_score(Y_test_max, Y_pred, average='micro')*100,4)\n",
        "  precision = np.round(precision_score(Y_test_max, Y_pred, average='micro')*100,4)\n",
        "  result = [\"CNN\", accuracy, bal_acc, recall,f1_weighted, f1_average, precision]\n",
        " \n",
        "  cm = confusion_matrix(Y_test_max, Y_pred)\n",
        "  plt.figure(figsize = (7,7))\n",
        "  sns.heatmap(cm, annot=True)\n",
        "  plt.show()\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('Model Accuracy for %s' % DataName)\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('Model loss for %s' % DataName)\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "  return result"
      ],
      "metadata": {
        "id": "cs20nU6AKkJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import roc_curve,auc\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "import tensorflow as tf\n",
        "# from tensorflow.keras import backend as K\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Input, Flatten\n",
        "from keras.layers import Dense, Dropout, Conv1D, MaxPool1D, GlobalMaxPool1D, Embedding, Activation\n",
        "from keras.layers import Dense, Input, LSTM, SimpleRNN, Embedding, Dropout, SpatialDropout1D, Activation, Conv1D,GRU\n",
        "from keras.layers import Conv1D, Bidirectional, GlobalMaxPool1D, MaxPooling1D, BatchNormalization, Add, Flatten\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from sklearn.cluster import KMeans\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import gensim\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "from pandas.core.common import SettingWithCopyWarning\n",
        "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)"
      ],
      "metadata": {
        "id": "_AGP4vEHe-wm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classification_metrics(test_labels, predicted_labels, model_name):\n",
        "  print()\n",
        "  accuracy = np.round(accuracy_score(test_labels, predicted_labels)*100,4)\n",
        "  bal_acc = np.round(balanced_accuracy_score(test_labels, predicted_labels)*100,4)\n",
        "  recall = np.round(recall_score(test_labels, predicted_labels, average='micro')*100,4)\n",
        "  f1_weighted = np.round(f1_score(test_labels, predicted_labels, average='weighted')*100,4)\n",
        "  f1_average = np.round(f1_score(test_labels, predicted_labels, average='micro')*100,4)\n",
        "  precision = np.round(precision_score(test_labels, predicted_labels, average='micro')*100,4)\n",
        "  result = [model_name.upper(), accuracy, bal_acc, recall,f1_weighted, f1_average, precision]\n",
        "  return result"
      ],
      "metadata": {
        "id": "hD-TheaYfJuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def baseline_models_experimental(df_experiments: pd.DataFrame, model_type: str):\n",
        "  df_temp = df_experiments.copy()\n",
        "  Y = df_temp.label\n",
        "  df_temp.drop(columns={'label'}, inplace = True)\n",
        "  X = df_temp\n",
        "  x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size= 0.3)\n",
        "  result_Final_exp = []\n",
        "  def Random_Forest_EXP(x_train, x_test, y_train, y_test):\n",
        "    forest = RandomForestClassifier()\n",
        "    forest = forest.fit(x_train, y_train)\n",
        "    result = forest.predict(x_test)\n",
        "    result_Random_Forest_EXP = classification_metrics(y_test, result, \"Random Forest EXP\")\n",
        "    result_Final_exp.append(result_Random_Forest_EXP)\n",
        "\n",
        "  def Decision_Tree_EXP(x_train, x_test, y_train, y_test):\n",
        "    modelDTC = DecisionTreeClassifier()\n",
        "    modelLR = modelDTC.fit(x_train, y_train)\n",
        "    result = modelLR.predict(x_test)\n",
        "    result_DT_EXP = classification_metrics(y_test, result, \"Decision Tree EXP\")\n",
        "    result_Final_exp.append(result_DT_EXP)\n",
        "\n",
        "  def KNN_EXP(x_train, x_test, y_train, y_test):\n",
        "    modelKNN = KNeighborsClassifier(n_neighbors=4)\n",
        "    modelKNN = modelKNN.fit(x_train, y_train)\n",
        "    result = modelKNN.predict(x_test)\n",
        "    classes_x=result\n",
        "    result_KNN_EXP = classification_metrics(y_test, classes_x, \"K Nearest Neighbors EXP\")\n",
        "    result_Final_exp.append(result_KNN_EXP)\n",
        "\n",
        "  def KMEANS_EXP(X: pd.DataFrame, Y: pd.DataFrame):\n",
        "\n",
        "    kmeans = KMeans(n_clusters=4, random_state=0, max_iter=1000, algorithm = 'auto')\n",
        "    kmeans.fit(X)\n",
        "    pred = kmeans.labels_\n",
        "    correct_labels = sum(Y == pred)\n",
        "    # print(\"Result: %d out of %d samples were correctly labeled.\" % (correct_labels, len(Y)), end=\"\\n\\n\")\n",
        "    result_KMeans_exp = classification_metrics(Y, pred, \"K Means EXP\")\n",
        "    result_Final_exp.append(result_KMeans_exp)\n",
        "\n",
        "  \n",
        "  Random_Forest_EXP(x_train, x_test, y_train, y_test)\n",
        "  Decision_Tree_EXP(x_train, x_test, y_train, y_test)\n",
        "  KNN_EXP(x_train, x_test, y_train, y_test)\n",
        "  KMEANS_EXP(X, Y)\n",
        "  result_cnn = cnn(df_experiments, \"CNN EXP\", 10)\n",
        "  result_Final_exp.append(result_cnn)\n",
        "  Pretty_Table = PrettyTable([\"Model\" , \"Accuracy\", \"Balanced Accuracy\", \"Recall\", \"F1-Weighted\", \"F1-Average\", \"Precision\"])\n",
        "  Pretty_Table.title = model_type.upper()\n",
        "  for x in result_Final_exp:\n",
        "    Pretty_Table.add_row(x)\n",
        "\n",
        "  print(Pretty_Table, end = \"\\n\")\n"
      ],
      "metadata": {
        "id": "NAf6dVfdfT1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_models_experimental(df_kms, \"BERT 768 Dimension Last Four Layers Means\")"
      ],
      "metadata": {
        "id": "bcwVuEu7flHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "decf410d-2070-4d89-8850-96791487b52c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "CNN EXP : (12008, 769)\n",
            "Epoch 1/10\n",
            "197/197 [==============================] - 32s 111ms/step - loss: 0.5300 - accuracy: 0.8160 - val_loss: 1.0645 - val_accuracy: 0.8677\n",
            "Epoch 2/10\n",
            "197/197 [==============================] - 22s 109ms/step - loss: 0.4026 - accuracy: 0.8637 - val_loss: 0.7808 - val_accuracy: 0.8711\n",
            "Epoch 3/10\n",
            "197/197 [==============================] - 22s 110ms/step - loss: 0.3784 - accuracy: 0.8661 - val_loss: 0.3889 - val_accuracy: 0.8663\n",
            "Epoch 4/10\n",
            "197/197 [==============================] - 21s 109ms/step - loss: 0.3655 - accuracy: 0.8704 - val_loss: 0.3751 - val_accuracy: 0.8606\n",
            "Epoch 5/10\n",
            "197/197 [==============================] - 22s 109ms/step - loss: 0.3567 - accuracy: 0.8777 - val_loss: 0.3927 - val_accuracy: 0.8592\n",
            "Epoch 6/10\n",
            "197/197 [==============================] - 21s 109ms/step - loss: 0.3389 - accuracy: 0.8835 - val_loss: 0.3631 - val_accuracy: 0.8668\n",
            "Epoch 7/10\n",
            "197/197 [==============================] - 21s 109ms/step - loss: 0.3296 - accuracy: 0.8816 - val_loss: 0.3604 - val_accuracy: 0.8744\n",
            "Epoch 8/10\n",
            "197/197 [==============================] - 21s 109ms/step - loss: 0.3159 - accuracy: 0.8886 - val_loss: 0.4135 - val_accuracy: 0.8639\n",
            "Epoch 9/10\n",
            "197/197 [==============================] - 22s 114ms/step - loss: 0.2968 - accuracy: 0.8921 - val_loss: 0.3950 - val_accuracy: 0.8677\n",
            "Epoch 10/10\n",
            "197/197 [==============================] - 21s 109ms/step - loss: 0.2797 - accuracy: 0.8993 - val_loss: 0.3843 - val_accuracy: 0.8682\n",
            "+---------------------------------------------------------------------------------------------------------+\n",
            "|                                BERT 768 DIMENSION LAST FOUR LAYERS MEANS                                |\n",
            "+-------------------------+----------+-------------------+---------+-------------+------------+-----------+\n",
            "|          Model          | Accuracy | Balanced Accuracy |  Recall | F1-Weighted | F1-Average | Precision |\n",
            "+-------------------------+----------+-------------------+---------+-------------+------------+-----------+\n",
            "|    RANDOM FOREST EXP    | 85.8451  |      84.8196      | 85.8451 |   85.8203   |  85.8451   |  85.8451  |\n",
            "|    DECISION TREE EXP    | 77.9906  |      77.4285      | 77.9906 |   78.0137   |  77.9906   |  77.9906  |\n",
            "| K NEAREST NEIGHBORS EXP | 83.6525  |      82.1996      | 83.6525 |    83.598   |  83.6525   |  83.6525  |\n",
            "|       K MEANS EXP       |  42.455  |      37.1802      |  42.455 |   45.0017   |   42.455   |   42.455  |\n",
            "|           CNN           | 85.8174  |      84.4914      | 85.8174 |   85.8111   |  85.8174   |  85.8174  |\n",
            "+-------------------------+----------+-------------------+---------+-------------+------------+-----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(df.embeddings)"
      ],
      "metadata": {
        "id": "w3Gc8ks21jFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtHlUgzfJf47",
        "outputId": "79d290f4-5582-490b-fe50-2ea187ce381a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12008,)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "VKpzDf3jJgiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=50)"
      ],
      "metadata": {
        "id": "rY3aQlz5JmLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ0R3ij3Joy9",
        "outputId": "6ff56bae-9e68-45aa-a858-4d4fc7355242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PCA(n_components=50)"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AQnlqcJCJzLq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}