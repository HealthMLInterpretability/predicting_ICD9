{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqTKLa6peZHB"
   },
   "source": [
    "## Replicating code/results from https://github.com/bvanaken/clinical-outcome-prediction  (Mortality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S_q_ZI0OUfLE"
   },
   "source": [
    "1. Clone Github profile and generated train/test/val datasets using task\n",
    "2. Uploaded datasets and concat to Google Colab\n",
    "3. Apply basic cleaning such as stopword removal, tokenization\n",
    "4. Create TFIDF vector (50k + columns)\n",
    "5. Train/Test with undersampling and no undersampling\n",
    "6. AUC ~ 0.78 (comparable to literature) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npbSye4TBeHP"
   },
   "source": [
    "### Installing and importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISGX7IjzecEx",
    "outputId": "e59bd6f7-69b1-45d3-8c64-09352bfae690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcjQFBlrA-Tm"
   },
   "outputs": [],
   "source": [
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T16:09:56.048500Z",
     "start_time": "2021-09-30T16:09:52.374797Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tu7AeAeieZHD",
    "outputId": "b816ac72-eaa4-4a64-a39a-9fe0da0c3147"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import contractions\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nltk.download('wordnet')\n",
    "all_stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ym1e-IyQBZQt"
   },
   "source": [
    "### Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-30T16:09:57.176085Z",
     "start_time": "2021-09-30T16:09:56.051517Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8bLrqN0eZHF",
    "outputId": "7efa50a2-2a85-46a7-fc50-266f478821aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       patient female past sudden onset midback pain ...\n",
       "1       shortness breath male newly discovered cardiom...\n",
       "2       mechanical fall hyperlipidemia presenting fall...\n",
       "3       nausea vomiting patient autoimmune hepatitis l...\n",
       "4       patient male presented patient laparoscopic ch...\n",
       "                              ...                        \n",
       "4903    worst headache life male transferred location ...\n",
       "4904    transfer macu hemodialysis line replacement po...\n",
       "4905    sudden onset severe headache spanish speaking ...\n",
       "4906    known lastname female multiple problem includi...\n",
       "4907    rectosigmoid colon cancer known firstname fema...\n",
       "Name: TEXT_cleaned, Length: 48684, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_results_test = pd.read_csv('/content/drive/MyDrive/MP_RESULTS/MP_IN_adm_test.csv')\n",
    "mp_results_train = pd.read_csv('/content/drive/MyDrive/MP_RESULTS/MP_IN_adm_train.csv')\n",
    "mp_results_val = pd.read_csv('/content/drive/MyDrive/MP_RESULTS/MP_IN_adm_val.csv')\n",
    "\n",
    "df = pd.concat([mp_results_test, mp_results_train, mp_results_val])\n",
    "df.shape\n",
    "\n",
    "def filter_admission_text(notes_df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter text information by section and only keep sections that are known on admission time.\n",
    "    \"\"\"\n",
    "    admission_sections = {\n",
    "        \"CHIEF_COMPLAINT\": \"chief complaint:\",\n",
    "        \"PRESENT_ILLNESS\": \"present illness:\",\n",
    "        \"MEDICAL_HISTORY\": \"medical history:\",\n",
    "        \"MEDICATION_ADM\": \"medications on admission:\",\n",
    "        \"ALLERGIES\": \"allergies:\",\n",
    "        \"PHYSICAL_EXAM\": \"physical exam:\",\n",
    "        \"FAMILY_HISTORY\": \"family history:\",\n",
    "        \"SOCIAL_HISTORY\": \"social history:\"\n",
    "    }\n",
    "\n",
    "    # replace linebreak indicators\n",
    "    notes_df['text'] = notes_df['text'].str.replace(r\"\\n\", r\"\\\\n\")\n",
    "\n",
    "    # extract each section by regex\n",
    "    for key in admission_sections.keys():\n",
    "        section = admission_sections[key]\n",
    "        notes_df[key] = notes_df.text.str.extract(r'(?i){}(.+?)\\\\n\\\\n[^(\\\\|\\d|\\.)]+?:'\n",
    "                                                  .format(section))\n",
    "\n",
    "        notes_df[key] = notes_df[key].str.replace(r'\\\\n', r' ')\n",
    "        notes_df[key] = notes_df[key].str.strip()\n",
    "        notes_df[key] = notes_df[key].fillna(\"\")\n",
    "        notes_df[notes_df[key].str.startswith(\"[]\")][key] = \"\"\n",
    "\n",
    "    # filter notes with missing main information\n",
    "#     notes_df = notes_df[(notes_df.CHIEF_COMPLAINT != \"\") | (notes_df.PRESENT_ILLNESS != \"\") |\n",
    "#                         (notes_df.MEDICAL_HISTORY != \"\")]\n",
    "\n",
    "    # add section headers and combine into TEXT_ADMISSION\n",
    "    notes_df = notes_df.assign(TEXT=\"CHIEF COMPLAINT: \" + notes_df.CHIEF_COMPLAINT.astype(str)\n",
    "                                    + '\\n\\n' +\n",
    "                                    \"PRESENT ILLNESS: \" + notes_df.PRESENT_ILLNESS.astype(str)\n",
    "                                    + '\\n\\n' +\n",
    "                                    \"MEDICAL HISTORY: \" + notes_df.MEDICAL_HISTORY.astype(str)\n",
    "                                    + '\\n\\n' +\n",
    "                                    \"MEDICATION ON ADMISSION: \" + notes_df.MEDICATION_ADM.astype(str)\n",
    "                                    + '\\n\\n' +\n",
    "                                    \"ALLERGIES: \" + notes_df.ALLERGIES.astype(str)\n",
    "                                    + '\\n\\n' +\n",
    "                                    \"PHYSICAL EXAM: \" + notes_df.PHYSICAL_EXAM.astype(str)\n",
    "                                    + '\\n\\n' +\n",
    "                                    \"FAMILY HISTORY: \" + notes_df.FAMILY_HISTORY.astype(str)\n",
    "                                    + '\\n\\n' +\n",
    "                                    \"SOCIAL HISTORY: \" + notes_df.SOCIAL_HISTORY.astype(str))\n",
    "\n",
    "    return notes_df\n",
    "\n",
    "df_filtered = filter_admission_text(df)\n",
    "\n",
    "my_stop_words = ['discharge', 'diagnosis', 'medications', 'medication', 'disposition', 'condition', 'instructions', \n",
    "                 'status', 'secondary', 'changes', 'instruction', 'change', 'home', 'name', 'hospital', 'daily',\n",
    "                'hour', 'follow', 'care', 'time', 'day', 'week', 'with', 'disp', 'discharged', 'admitted', \n",
    "                 'namepattern', 'none', 'chief', 'complaint', 'physical', 'exam', 'present', 'illness', 'family','year', 'history','admission', 'social', 'medical', 'allergies']\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "def clean_string(s):\n",
    "    # Remove all the special characters\n",
    "    s_clean = re.sub(r'\\W', ' ', s)\n",
    "    s_clean = re.sub('_', ' ', s)\n",
    "    # Remove new line characters\n",
    "    s_clean = s_clean.replace(\"\\n\", ' ')\n",
    "    # Punctuation\n",
    "    s_clean = re.sub(r'[^\\w\\s]', ' ', s_clean)\n",
    "    # remove all single characters\n",
    "    s_clean = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', s_clean)\n",
    "    # Remove single characters from the start\n",
    "    s_clean = re.sub(r'\\^[a-zA-Z]\\s+', ' ', s_clean) \n",
    "    # Substituting multiple spaces with single space\n",
    "    s_clean = re.sub(r'\\s+', ' ', s_clean, flags=re.I)\n",
    "    # Removing prefixed 'b'\n",
    "    s_clean = re.sub(r'^b\\s+', '', s_clean)\n",
    "    #Removing Numbers\n",
    "    s_clean = ''.join(i for i in s_clean if not i.isdigit())\n",
    "    #Removing Stopwords\n",
    "    s_clean = ' '.join([i for i in s_clean.split() if not i in all_stopwords])\n",
    "    #Removing certain sized words\n",
    "    s_clean = ' '.join([i for i in s_clean.split() if len(i)>3])\n",
    "    # Contractions\n",
    "    s_clean = contractions.fix(s_clean)\n",
    "    # Converting to Lowercase\n",
    "    s_clean = s_clean.lower()\n",
    "    # Lemmatization\n",
    "    s_clean = s_clean.split()\n",
    "    s_clean = [stemmer.lemmatize(word) for word in s_clean]\n",
    "    s_clean = ' '.join(s_clean)\n",
    "    #Removing my_stop_words\n",
    "    s_clean = ' '.join([i for i in s_clean.split() if not i in my_stop_words])\n",
    "    return s_clean\n",
    "\n",
    "df_filtered['TEXT_cleaned'] = [clean_string(s) for s in df_filtered['TEXT']]\n",
    "df_filtered['TEXT_cleaned']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIuCDshsA38z"
   },
   "source": [
    "### TFIDF Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-30T16:09:52.366Z"
    },
    "id": "74FQEFW5eZHI"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df_filtered['TEXT_cleaned'])\n",
    "y = df_filtered['hospital_expire_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-09-30T16:09:52.367Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "cuMV66zmeZHI",
    "outputId": "e3100415-fe67-46b4-ff7f-549143aab8ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaainfrarenal</th>\n",
       "      <th>aaax</th>\n",
       "      <th>aabdominal</th>\n",
       "      <th>aabsent</th>\n",
       "      <th>aaccident</th>\n",
       "      <th>aacyclovir</th>\n",
       "      <th>aadls</th>\n",
       "      <th>aado</th>\n",
       "      <th>aads</th>\n",
       "      <th>aafter</th>\n",
       "      <th>aagain</th>\n",
       "      <th>aair</th>\n",
       "      <th>aand</th>\n",
       "      <th>aando</th>\n",
       "      <th>aandox</th>\n",
       "      <th>aaoriented</th>\n",
       "      <th>aaox</th>\n",
       "      <th>aapearing</th>\n",
       "      <th>aaro</th>\n",
       "      <th>aaspirin</th>\n",
       "      <th>aassociated</th>\n",
       "      <th>abacavir</th>\n",
       "      <th>abacivir</th>\n",
       "      <th>abagovomab</th>\n",
       "      <th>abagovomag</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abaout</th>\n",
       "      <th>abasia</th>\n",
       "      <th>abassi</th>\n",
       "      <th>abatacept</th>\n",
       "      <th>abate</th>\n",
       "      <th>abated</th>\n",
       "      <th>abatement</th>\n",
       "      <th>abates</th>\n",
       "      <th>abating</th>\n",
       "      <th>abbd</th>\n",
       "      <th>abbdominal</th>\n",
       "      <th>abberancy</th>\n",
       "      <th>abberency</th>\n",
       "      <th>...</th>\n",
       "      <th>zonisamide</th>\n",
       "      <th>zonisomide</th>\n",
       "      <th>zopenex</th>\n",
       "      <th>zophran</th>\n",
       "      <th>zophrin</th>\n",
       "      <th>zoster</th>\n",
       "      <th>zostrix</th>\n",
       "      <th>zosy</th>\n",
       "      <th>zosyb</th>\n",
       "      <th>zosyn</th>\n",
       "      <th>zosysn</th>\n",
       "      <th>zovirax</th>\n",
       "      <th>zoysn</th>\n",
       "      <th>zoysyn</th>\n",
       "      <th>zozyn</th>\n",
       "      <th>zpack</th>\n",
       "      <th>zpak</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zxam</th>\n",
       "      <th>zyban</th>\n",
       "      <th>zydis</th>\n",
       "      <th>zydone</th>\n",
       "      <th>zydus</th>\n",
       "      <th>zyflo</th>\n",
       "      <th>zygoesophageal</th>\n",
       "      <th>zygoma</th>\n",
       "      <th>zygomal</th>\n",
       "      <th>zygomatic</th>\n",
       "      <th>zygomatico</th>\n",
       "      <th>zygomaticomaxillary</th>\n",
       "      <th>zygomycetes</th>\n",
       "      <th>zygomycosis</th>\n",
       "      <th>zymar</th>\n",
       "      <th>zyprexa</th>\n",
       "      <th>zyrtec</th>\n",
       "      <th>zysyn</th>\n",
       "      <th>zytec</th>\n",
       "      <th>zytrec</th>\n",
       "      <th>zyvox</th>\n",
       "      <th>zyvoxx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56591 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaainfrarenal  aaax  aabdominal  aabsent  ...  zytec  zytrec  zyvox  zyvoxx\n",
       "0            0.0   0.0         0.0      0.0  ...    0.0     0.0    0.0     0.0\n",
       "1            0.0   0.0         0.0      0.0  ...    0.0     0.0    0.0     0.0\n",
       "2            0.0   0.0         0.0      0.0  ...    0.0     0.0    0.0     0.0\n",
       "3            0.0   0.0         0.0      0.0  ...    0.0     0.0    0.0     0.0\n",
       "4            0.0   0.0         0.0      0.0  ...    0.0     0.0    0.0     0.0\n",
       "\n",
       "[5 rows x 56591 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "U7fuS8Ur7iyL"
   },
   "outputs": [],
   "source": [
    "#No undersampling:\n",
    "cv = KFold(n_splits=10, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "feature_importances = pd.DataFrame({'features': tfidf_df.columns, 'importance': rf.feature_importances_})\n",
    "y_pred_prob = rf.predict_proba(X_test)\n",
    "y_pred = rf.predict(X_test)\n",
    "lr_auc = metrics.roc_auc_score(y_test, y_pred_prob[:, 1])\n",
    "scores = cross_val_score(rf, X_test, y_test, cv=cv, scoring = 'f1_micro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GlQWeAW5K69X",
    "outputId": "ddb9ffc0-f1ad-40c1-8525-6f993878faef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mortality Prediction: No random undersampling\n",
      "AUC:  0.772340974244477\n",
      "F1 score: 0.9102739726027397\n",
      "Feature importance:\n",
      "           features  importance\n",
      "26945     intubated    0.007139\n",
      "53691  unresponsive    0.003213\n",
      "1621        allergy    0.002896\n",
      "19470          file    0.002436\n",
      "20270         found    0.002128\n",
      "36951       patient    0.002036\n",
      "52110   transferred    0.001907\n",
      "36118          pain    0.001895\n",
      "27862         known    0.001865\n",
      "11233       corneal    0.001841\n"
     ]
    }
   ],
   "source": [
    "print('Mortality Prediction: No random undersampling')\n",
    "print('AUC: ', lr_auc)\n",
    "print('F1 score:', scores.max())\n",
    "print('Feature importance:')\n",
    "print(feature_importances.sort_values(by='importance', ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SRFae0-zu1UR"
   },
   "outputs": [],
   "source": [
    "#Random undersampling\n",
    "cv = KFold(n_splits=10, random_state=1)\n",
    "steps = [('under', RandomUnderSampler()), ('model', RandomForestClassifier())]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "feature_importances_under = pd.DataFrame({'features': tfidf_df.columns, 'importance': pipeline[1].feature_importances_})\n",
    "y_pred_prob_under = pipeline.predict_proba(X_test)\n",
    "y_pred_under = pipeline.predict(X_test)\n",
    "lr_auc_under = metrics.roc_auc_score(y_test, y_pred_prob_under[:, 1])\n",
    "scores_under = cross_val_score(pipeline, X_test, y_test, cv=cv, scoring = 'f1_micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "63DF6VXu0TW-",
    "outputId": "12ca8da0-e1cf-43e2-ebc5-d83f378ea2a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mortality Prediction - TFIDF: With random undersampling\n",
      "tfidf df shape:  (48684, 56591)\n",
      "AUC:  0.7826861642993256\n",
      "F1 score: 0.7143835616438357\n",
      "Feature importance:\n",
      "           features  importance\n",
      "26945     intubated    0.007066\n",
      "53691  unresponsive    0.004185\n",
      "1621        allergy    0.004088\n",
      "47081          soft    0.003341\n",
      "20270         found    0.003305\n",
      "52110   transferred    0.003250\n",
      "36118          pain    0.003111\n",
      "18864       failure    0.002806\n",
      "27862         known    0.002724\n",
      "15349          drug    0.002688\n"
     ]
    }
   ],
   "source": [
    "print('Mortality Prediction - TFIDF: With random undersampling')\n",
    "print('tfidf df shape: ', tfidf_df.shape)\n",
    "print('AUC: ', lr_auc_under)\n",
    "print('F1 score:', scores_under.max())\n",
    "print('Feature importance:')\n",
    "print(feature_importances_under.sort_values(by='importance', ascending=False)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOAolQykKu5Q",
    "outputId": "aef49f95-5b03-4056-f5a4-2480a691ddbb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "scores_under_bal = cross_val_score(pipeline, X_test, y_test, cv=cv, scoring = 'balanced_accuracy')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Replicating results-TFIDF-prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
