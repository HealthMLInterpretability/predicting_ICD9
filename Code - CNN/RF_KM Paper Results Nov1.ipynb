{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T03:44:08.808549Z",
     "start_time": "2021-11-02T03:44:08.802531Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T01:39:23.544801Z",
     "start_time": "2021-11-02T01:39:23.379669Z"
    }
   },
   "outputs": [],
   "source": [
    "df_TFIDF40 = pd.read_csv('input_ICD9_TFIDF_40.csv')\n",
    "df_TM5 = pd.read_csv('input_ICD9_TM_5.csv')\n",
    "df_TM20 = pd.read_csv('input_ICD9_TM_20.csv')\n",
    "df_TM30 = pd.read_csv('input_ICD9_TM_30.csv')\n",
    "df_TM30.rename(columns={'top_icd': 'ICD9'}, inplace=True)\n",
    "df_TM39 = pd.read_csv('input_ICD9_TM_39.csv')\n",
    "\n",
    "df_list = [df_TFIDF40, df_TM5, df_TM20, df_TM30, df_TM39]\n",
    "files_list = ['TFIDF_40', 'TM_5', 'TM_20', 'TM_30', 'TM_39']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:06:05.157914Z",
     "start_time": "2021-11-02T02:06:05.144947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True]\n",
      "[(5936, 41), (11537, 6), (11537, 21), (11537, 31), (11537, 40)]\n",
      "[414    1792\n",
      "38     1654\n",
      "410    1605\n",
      "424     885\n",
      "Name: ICD9, dtype: int64, 414    3502\n",
      "38     3184\n",
      "410    3175\n",
      "424    1676\n",
      "Name: ICD9, dtype: int64, 414    3502\n",
      "38     3184\n",
      "410    3175\n",
      "424    1676\n",
      "Name: ICD9, dtype: int64, 414    3502\n",
      "38     3184\n",
      "410    3175\n",
      "424    1676\n",
      "Name: ICD9, dtype: int64, 414    3502\n",
      "38     3184\n",
      "410    3175\n",
      "424    1676\n",
      "Name: ICD9, dtype: int64]\n"
     ]
    }
   ],
   "source": [
    "# Some data quality checks\n",
    "# Label is consistent\n",
    "print([True for df in df_list if 'ICD9' in df.columns])\n",
    "print([df.shape for df in df_list])\n",
    "print([df['ICD9'].value_counts() for df in df_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T03:19:11.107770Z",
     "start_time": "2021-11-02T03:19:11.092797Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_classification_metrics_rf(df: pd.DataFrame, label_col:str):\n",
    "    '''\n",
    "    Get accuracy and F1 metrics from Random Forest\n",
    "    '''\n",
    "    # Train test split\n",
    "    X = df.drop(columns=[label_col])\n",
    "    y = df[label_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Random Forest Classifer\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    rf_prob = rf.predict_proba(X_test)\n",
    "    rf_acc = balanced_accuracy_score(y_test, rf_pred)\n",
    "    rf_f1 = f1_score(y_test, rf_pred, average = 'weighted')\n",
    "    rf_auc = roc_auc_score(y_test, rf_prob, multi_class='ovr', average='macro')\n",
    "    \n",
    "    # Construct results\n",
    "    results = dict()\n",
    "    results['pred'], results['pred_prob'] = rf_pred, rf_prob\n",
    "    results['acc'], results['f1'], results['auc'] = rf_acc, rf_f1, rf_auc\n",
    "    results['model'] = rf\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T03:46:36.111887Z",
     "start_time": "2021-11-02T03:46:36.087198Z"
    }
   },
   "outputs": [],
   "source": [
    "def F1(pred, true, clabel): # Accuracy / F1 / Precision / Recall Output\n",
    "    TP,FP,FN=0,0,0 \n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == true[i] and pred[i] == clabel: # only for minority class.\n",
    "            TP+=1\n",
    "        if pred[i] == clabel and true[i] != clabel:\n",
    "            FP+=1\n",
    "        if pred[i] != clabel and true[i] == clabel:\n",
    "            FN+=1\n",
    "    if TP==0:\n",
    "        precision=0\n",
    "        recall=0\n",
    "        f1=0\n",
    "    else:\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        f1 = 2*TP/(2*TP+FP+FN)\n",
    "\n",
    "    return precision,recall,f1\n",
    "\n",
    "\n",
    "def get_classification_metrics_km(df: pd.DataFrame, label_col:str): #PY Double check\n",
    "    '''\n",
    "    Get accuracy and F1 metrics from Kmeans\n",
    "    '''\n",
    "    # Train test split\n",
    "    X = df.drop(columns=[label_col])\n",
    "    y = df[label_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # Kmeans Clustering\n",
    "    km = KMeans()\n",
    "    km.fit(X_train)\n",
    "    km_pred = km.predict(X_test)\n",
    "    \n",
    "    ICD9_CODE_map = {\n",
    "    '414':  0, #chronic heart\n",
    "    '38':  1, #sepsis\n",
    "    '410': 2, #heart attack\n",
    "    '424': 3, #diseases of endocardium\n",
    "    }\n",
    "    \n",
    "    y_train_km = y_train.map(ICD9_CODE_map)\n",
    "    y_test_km = y_test.map(ICD9_CODE_map)\n",
    "    pred = kmeans.labels_\n",
    "    true = y_test_km\n",
    "    \n",
    "    acc=0\n",
    "    max = 0\n",
    "    predTemp=[-1,-1,-1,-1]\n",
    "    predNew=[-1]*len(pred)\n",
    "    predAssign = pd.Series(pred)\n",
    "    predFinal=[-1]*len(pred)\n",
    "\n",
    "    for i in range(4):\n",
    "        predTemp[i]=0\n",
    "        for j in range(4):\n",
    "            if j!=i:\n",
    "                predTemp[j]=1\n",
    "            else:\n",
    "                continue\n",
    "            for k in range(4):\n",
    "                if k!=i and k!=j:\n",
    "                    predTemp[k]=2\n",
    "                else:\n",
    "                    continue\n",
    "                for l in range(4):\n",
    "                    if l!=i and l!=k and l!=j:\n",
    "                        predTemp[l]=3\n",
    "                        pred_map = {\n",
    "                            0: predTemp[0],\n",
    "                            1: predTemp[1],\n",
    "                            2: predTemp[2],\n",
    "                            3: predTemp[3],\n",
    "                        }\n",
    "                        predNew = predAssign.map(pred_map)\n",
    "                        predNew = predNew.values\n",
    "                        acc = accuracy_score(true, predNew)\n",
    "                        if acc > max: \n",
    "                            max = acc\n",
    "                            predFinal = predNew  \n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "    #Assign new class to pred.\n",
    "    precision_c0,recall_c0,f1_c0=F1(predFinal,true.tolist(),0)\n",
    "    precision_c1,recall_c1,f1_c1=F1(predFinal,true.tolist(),1)\n",
    "    precision_c2,recall_c2,f1_c2=F1(predFinal,true.tolist(),2)\n",
    "    precision_c3,recall_c3,f1_c3=F1(predFinal,true.tolist(),3)\n",
    "\n",
    "    preAvg=(precision_c0+precision_c1+precision_c2+precision_c3)/4\n",
    "    reAvg=(recall_c0+recall_c1+recall_c2+recall_c3)/4\n",
    "    f1Avg=(f1_c0+f1_c1+f1_c2+f1_c3)/4\n",
    "    \n",
    "    # Weighted F1 (PY double check)\n",
    "    f1Weighted = np.average([f1_c0, f1_c1, f1_c2, f1_c3], weights=[len(predFinal==0), len(predFinal==1), len(predFinal==2), len(predFinal==3)])\n",
    "    \n",
    "    # Accuracy\n",
    "    bal_acc = balanced_accuracy_score(true, predFinal)\n",
    "    \n",
    "    # Results\n",
    "    results = dict()\n",
    "    results['pred'] = rf_pred, pred\n",
    "    results['acc'], results['f1'], results['f1_weighted'] = bal_acc, f1Avg, f1Weighted\n",
    "    results['model'] = km\n",
    "    \n",
    "    return results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T03:21:14.201836Z",
     "start_time": "2021-11-02T03:21:05.480343Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_results_list = [get_classification_metrics_rf(df, 'ICD9') for df in df_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T03:46:39.214079Z",
     "start_time": "2021-11-02T03:46:38.710453Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-58afe3475e08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkm_results_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_classification_metrics_km\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ICD9'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-49-58afe3475e08>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mkm_results_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_classification_metrics_km\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ICD9'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-48-668477b9398b>\u001b[0m in \u001b[0;36mget_classification_metrics_km\u001b[1;34m(df, label_col)\u001b[0m\n\u001b[0;32m     77\u001b[0m                         \u001b[0mpredNew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredAssign\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                         \u001b[0mpredNew\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredNew\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredNew\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                             \u001b[0mmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"multilabel\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"f\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"continuous\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    114\u001b[0m             raise ValueError(\n\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m--> 116\u001b[1;33m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m                 )\n\u001b[0;32m    118\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "km_results_list = [get_classification_metrics_km(df, 'ICD9') for df in df_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
